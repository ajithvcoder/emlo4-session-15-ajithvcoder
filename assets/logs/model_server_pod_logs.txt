INFO:     Started server process [1]
INFO:     Waiting for application startup.
2025-01-17 18:25:35,482 - ModelServer - INFO - Initializing model server on host model-server-7bb6747795-hmcnf
2025-01-17 18:25:35,482 - ModelServer - INFO - Loading model: mambaout_femto.in1k
2025-01-17 18:25:35,973 - ModelServer - INFO - Model loaded successfully
2025-01-17 18:25:35,974 - ModelServer - INFO - Creating Redis connection pool: host=redis-service, port=6379
2025-01-17 18:25:35,974 - ModelServer - INFO - Model server initialization complete
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:80 (Press CTRL+C to quit)
Loading ONNX model...
Model loaded successfully
INFO:     192.168.64.192:3078 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:62424 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:39378 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:26802 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:14670 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:14640 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:46300 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:14138 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:3044 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:49652 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:56750 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:50254 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:11962 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:38854 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:18322 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:53992 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:15246 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:4784 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:22590 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:44956 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:40222 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:35466 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:48760 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:23882 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:21650 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:48764 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:30598 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:27570 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:45848 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:37408 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:56714 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:61354 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:14380 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:22284 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:33802 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:48738 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:41496 - "GET /health HTTP/1.1" 200 OK
INFO:     192.168.4.26:45624 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:49826 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:24260 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:39136 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:46990 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:1542 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:46992 - "GET /health HTTP/1.1" 200 OK
2025-01-17 18:30:19,777 - ModelServer - INFO - Received inference request
2025-01-17 18:30:20,105 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:30:20,109 - ModelServer - INFO - Received inference request
2025-01-17 18:30:20,414 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:30:20,429 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:59122 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:30:20,431 - ModelServer - INFO - Received inference request
2025-01-17 18:30:20,729 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:30:20,740 - ModelServer - INFO - Received inference request
2025-01-17 18:30:21,040 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:30:21,041 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:1568 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:30:21,043 - ModelServer - INFO - Received inference request
2025-01-17 18:30:21,353 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:30:21,358 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:59124 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:30:21,378 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:1554 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:30:21,388 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:47006 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:30:21,409 - ModelServer - INFO - Received inference request
2025-01-17 18:30:21,750 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:30:21,758 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:46992 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:30:21,779 - ModelServer - INFO - Received inference request
2025-01-17 18:30:22,042 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:30:22,044 - ModelServer - INFO - Received inference request
2025-01-17 18:30:22,343 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:30:22,344 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:59124 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:30:22,345 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:47006 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.4.26:62292 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:5776 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:41108 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:26596 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:15652 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:64208 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:35780 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:50800 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:31:01,818 - ModelServer - INFO - Received inference request
2025-01-17 18:31:02,125 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:02,129 - ModelServer - INFO - Received inference request
2025-01-17 18:31:02,497 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:02,509 - ModelServer - INFO - Received inference request
2025-01-17 18:31:02,837 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:02,838 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40224 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:02,839 - ModelServer - INFO - Received inference request
2025-01-17 18:31:03,176 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:03,189 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50810 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:03,190 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50806 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:03,192 - ModelServer - INFO - Received inference request
2025-01-17 18:31:03,516 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:03,517 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40240 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:03,519 - ModelServer - INFO - Received inference request
2025-01-17 18:31:03,805 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:03,815 - ModelServer - INFO - Received inference request
2025-01-17 18:31:04,137 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:04,148 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50820 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:04,150 - ModelServer - INFO - Received inference request
2025-01-17 18:31:04,492 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.47.42:40250 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:31:04,495 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50814 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:04,498 - ModelServer - INFO - Received inference request
2025-01-17 18:31:04,850 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:04,851 - ModelServer - INFO - Received inference request
2025-01-17 18:31:05,161 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:05,163 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50810 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:05,164 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40224 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:05,165 - ModelServer - INFO - Received inference request
2025-01-17 18:31:05,450 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:05,454 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50806 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:05,455 - ModelServer - INFO - Received inference request
2025-01-17 18:31:05,751 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:05,753 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50822 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:05,756 - ModelServer - INFO - Received inference request
2025-01-17 18:31:06,052 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:06,053 - ModelServer - INFO - Received inference request
2025-01-17 18:31:06,395 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:06,409 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:52258 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:06,410 - ModelServer - INFO - Received inference request
2025-01-17 18:31:06,745 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:06,748 - ModelServer - INFO - Received inference request
2025-01-17 18:31:07,035 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:07,040 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50828 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:07,046 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50814 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:07,048 - ModelServer - INFO - Received inference request
2025-01-17 18:31:07,343 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:07,345 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50810 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:07,349 - ModelServer - INFO - Received inference request
2025-01-17 18:31:07,655 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:07,656 - ModelServer - INFO - Received inference request
2025-01-17 18:31:07,922 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:07,924 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:52272 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:07,929 - ModelServer - INFO - Received inference request
2025-01-17 18:31:08,207 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:08,213 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40240 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:08,218 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50822 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:08,220 - ModelServer - INFO - Received inference request
2025-01-17 18:31:08,543 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:08,545 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50814 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:08,546 - ModelServer - INFO - Received inference request
2025-01-17 18:31:08,887 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:08,889 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50806 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:08,890 - ModelServer - INFO - Received inference request
2025-01-17 18:31:09,242 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:09,249 - ModelServer - INFO - Received inference request
2025-01-17 18:31:09,526 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:09,539 - ModelServer - INFO - Received inference request
2025-01-17 18:31:09,854 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:09,862 - ModelServer - INFO - Received inference request
2025-01-17 18:31:10,158 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:10,160 - ModelServer - INFO - Received inference request
2025-01-17 18:31:10,429 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:10,439 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:52254 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:10,440 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40224 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:10,441 - ModelServer - INFO - Received inference request
2025-01-17 18:31:10,791 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:10,792 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:52272 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:10,795 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40240 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:10,799 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50814 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:10,801 - ModelServer - INFO - Received inference request
2025-01-17 18:31:11,152 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:11,160 - ModelServer - INFO - Received inference request
2025-01-17 18:31:11,479 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.4.26:50858 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:31:11,480 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:12020 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:11,481 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40266 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:11,482 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40240 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:11,496 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50842 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:11,497 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50820 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:11,499 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50810 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:11,502 - ModelServer - INFO - Received inference request
2025-01-17 18:31:11,848 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:11,850 - ModelServer - INFO - Received inference request
2025-01-17 18:31:12,155 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:12,169 - ModelServer - INFO - Received inference request
2025-01-17 18:31:12,504 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:12,509 - ModelServer - INFO - Received inference request
2025-01-17 18:31:12,858 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:12,860 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50828 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:12,869 - ModelServer - INFO - Received inference request
2025-01-17 18:31:13,164 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:13,165 - ModelServer - INFO - Received inference request
2025-01-17 18:31:13,475 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:13,489 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50806 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:13,489 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40224 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:13,490 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50820 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:13,491 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40240 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:13,494 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50814 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:13,518 - ModelServer - INFO - Received inference request
2025-01-17 18:31:13,849 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:13,850 - ModelServer - INFO - Received inference request
2025-01-17 18:31:14,159 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:14,161 - ModelServer - INFO - Received inference request
2025-01-17 18:31:14,552 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:14,553 - ModelServer - INFO - Received inference request
2025-01-17 18:31:14,898 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:14,900 - ModelServer - INFO - Received inference request
2025-01-17 18:31:15,201 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:15,203 - ModelServer - INFO - Received inference request
2025-01-17 18:31:15,517 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:15,525 - ModelServer - INFO - Received inference request
2025-01-17 18:31:15,866 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:15,879 - ModelServer - INFO - Received inference request
2025-01-17 18:31:16,195 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:16,209 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50820 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,210 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50810 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,211 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40240 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,212 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50806 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,213 - ModelServer - INFO - Received inference request
2025-01-17 18:31:16,538 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:16,540 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50828 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,541 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40224 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,541 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50814 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,542 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:52254 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,546 - ModelServer - INFO - Received inference request
2025-01-17 18:31:16,875 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.64.192:8040 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:31:16,880 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50842 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:16,889 - ModelServer - INFO - Received inference request
2025-01-17 18:31:17,170 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:17,179 - ModelServer - INFO - Received inference request
2025-01-17 18:31:17,508 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:17,509 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:12020 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:17,511 - ModelServer - INFO - Received inference request
2025-01-17 18:31:17,797 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:17,809 - ModelServer - INFO - Received inference request
2025-01-17 18:31:18,138 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:18,140 - ModelServer - INFO - Received inference request
2025-01-17 18:31:18,421 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:18,423 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50806 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:18,424 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50810 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:18,425 - ModelServer - INFO - Received inference request
2025-01-17 18:31:18,726 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.47.42:13992 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:31:18,740 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40240 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:18,740 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:52254 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:18,743 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50814 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:18,744 - ModelServer - INFO - Received inference request
2025-01-17 18:31:19,097 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:19,109 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40224 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:19,111 - ModelServer - INFO - Received inference request
2025-01-17 18:31:19,401 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:19,409 - ModelServer - INFO - Received inference request
2025-01-17 18:31:19,742 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:19,749 - ModelServer - INFO - Received inference request
2025-01-17 18:31:20,045 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:20,050 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:8050 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:20,057 - ModelServer - INFO - Received inference request
2025-01-17 18:31:20,316 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:20,329 - ModelServer - INFO - Received inference request
2025-01-17 18:31:20,607 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:20,608 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50820 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:20,619 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:13994 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:20,619 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50842 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:20,621 - ModelServer - INFO - Received inference request
2025-01-17 18:31:20,911 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:20,917 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50806 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:20,928 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40240 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:20,931 - ModelServer - INFO - Received inference request
2025-01-17 18:31:21,246 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:21,248 - ModelServer - INFO - Received inference request
2025-01-17 18:31:21,598 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:21,599 - ModelServer - INFO - Received inference request
2025-01-17 18:31:21,914 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:21,920 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:8052 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:21,929 - ModelServer - INFO - Received inference request
2025-01-17 18:31:22,283 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:22,284 - ModelServer - INFO - Received inference request
2025-01-17 18:31:22,591 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:22,592 - ModelServer - INFO - Received inference request
2025-01-17 18:31:22,963 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:22,965 - ModelServer - INFO - Received inference request
2025-01-17 18:31:23,241 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:23,242 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:40224 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:23,243 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:52254 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:23,244 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50810 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:23,245 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:50820 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:23,245 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50842 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:23,246 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50814 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:23,247 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50828 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.4.26:4042 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:22686 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:53516 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:5904 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:56338 - "GET /health HTTP/1.1" 200 OK
2025-01-17 18:31:41,623 - ModelServer - INFO - Received inference request
2025-01-17 18:31:41,990 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:41,991 - ModelServer - INFO - Received inference request
2025-01-17 18:31:42,328 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:42,329 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56352 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:42,332 - ModelServer - INFO - Received inference request
2025-01-17 18:31:42,622 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:42,639 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52052 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:42,640 - ModelServer - INFO - Received inference request
2025-01-17 18:31:42,950 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:42,959 - ModelServer - INFO - Received inference request
2025-01-17 18:31:43,249 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:43,250 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:43,252 - ModelServer - INFO - Received inference request
2025-01-17 18:31:43,550 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:43,552 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:43,553 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:43,559 - ModelServer - INFO - Received inference request
2025-01-17 18:31:43,870 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:43,872 - ModelServer - INFO - Received inference request
2025-01-17 18:31:44,170 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:44,174 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55568 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:44,178 - ModelServer - INFO - Received inference request
2025-01-17 18:31:44,549 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:44,550 - ModelServer - INFO - Received inference request
2025-01-17 18:31:44,842 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:44,849 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:44,850 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52052 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:44,851 - ModelServer - INFO - Received inference request
2025-01-17 18:31:45,127 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:45,133 - ModelServer - INFO - Received inference request
2025-01-17 18:31:45,419 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:45,420 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:45,421 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:45,425 - ModelServer - INFO - Received inference request
2025-01-17 18:31:45,734 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:45,747 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52066 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:45,749 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:45,751 - ModelServer - INFO - Received inference request
2025-01-17 18:31:46,065 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:46,079 - ModelServer - INFO - Received inference request
2025-01-17 18:31:46,389 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:46,391 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:46,392 - ModelServer - INFO - Received inference request
2025-01-17 18:31:46,693 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:46,694 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:46,695 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.64.192:20304 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:31:46,704 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:46,705 - ModelServer - INFO - Received inference request
2025-01-17 18:31:47,023 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:47,025 - ModelServer - INFO - Received inference request
2025-01-17 18:31:47,332 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:47,334 - ModelServer - INFO - Received inference request
2025-01-17 18:31:47,615 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:47,629 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20306 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:47,631 - ModelServer - INFO - Received inference request
2025-01-17 18:31:47,952 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:47,959 - ModelServer - INFO - Received inference request
2025-01-17 18:31:48,271 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:48,279 - ModelServer - INFO - Received inference request
2025-01-17 18:31:48,596 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:48,609 - ModelServer - INFO - Received inference request
2025-01-17 18:31:48,896 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:48,909 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:48,910 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55588 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:48,911 - ModelServer - INFO - Received inference request
2025-01-17 18:31:49,201 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:49,202 - ModelServer - INFO - Received inference request
2025-01-17 18:31:49,532 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.47.42:8518 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:31:49,540 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:49,541 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:49,541 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:8510 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:49,543 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:49,549 - ModelServer - INFO - Received inference request
2025-01-17 18:31:49,856 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:49,869 - ModelServer - INFO - Received inference request
2025-01-17 18:31:50,176 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:50,189 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55568 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:50,190 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:50,191 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20306 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:50,193 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:50,210 - ModelServer - INFO - Received inference request
2025-01-17 18:31:50,524 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:50,539 - ModelServer - INFO - Received inference request
2025-01-17 18:31:50,911 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:50,912 - ModelServer - INFO - Received inference request
2025-01-17 18:31:51,224 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:51,229 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:51,230 - ModelServer - INFO - Received inference request
2025-01-17 18:31:51,553 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:51,559 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:51,568 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:51,570 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:51,589 - ModelServer - INFO - Received inference request
2025-01-17 18:31:51,904 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:51,909 - ModelServer - INFO - Received inference request
2025-01-17 18:31:52,249 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:52,251 - ModelServer - INFO - Received inference request
2025-01-17 18:31:52,599 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:52,609 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:52,610 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:52,610 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:52,858 - ModelServer - INFO - Received inference request
2025-01-17 18:31:53,108 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:53,109 - ModelServer - INFO - Received inference request
2025-01-17 18:31:53,414 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:53,440 - ModelServer - INFO - Received inference request
2025-01-17 18:31:53,753 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:53,769 - ModelServer - INFO - Received inference request
2025-01-17 18:31:54,109 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:54,111 - ModelServer - INFO - Received inference request
2025-01-17 18:31:54,493 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:54,494 - ModelServer - INFO - Received inference request
2025-01-17 18:31:54,786 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:54,787 - ModelServer - INFO - Received inference request
2025-01-17 18:31:55,085 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:55,099 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,100 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,101 - ModelServer - INFO - Received inference request
2025-01-17 18:31:55,418 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:55,420 - ModelServer - INFO - Received inference request
2025-01-17 18:31:55,718 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:55,719 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,720 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,720 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,721 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,722 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20306 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,725 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,729 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55568 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:55,733 - ModelServer - INFO - Received inference request
2025-01-17 18:31:56,040 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:56,042 - ModelServer - INFO - Received inference request
2025-01-17 18:31:56,378 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:56,380 - ModelServer - INFO - Received inference request
2025-01-17 18:31:56,678 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:56,679 - ModelServer - INFO - Received inference request
2025-01-17 18:31:57,015 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:57,029 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:57,030 - ModelServer - INFO - Received inference request
2025-01-17 18:31:57,330 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:57,332 - ModelServer - INFO - Received inference request
2025-01-17 18:31:57,600 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.4.26:3686 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:31:57,610 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20306 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:57,610 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:57,611 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:57,612 - ModelServer - INFO - Received inference request
2025-01-17 18:31:57,872 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:57,889 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:57,891 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:57,892 - ModelServer - INFO - Received inference request
2025-01-17 18:31:58,164 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:58,165 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:58,166 - ModelServer - INFO - Received inference request
2025-01-17 18:31:58,475 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:58,489 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55568 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:58,490 - ModelServer - INFO - Received inference request
2025-01-17 18:31:58,790 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:58,791 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:58,792 - ModelServer - INFO - Received inference request
2025-01-17 18:31:59,070 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:59,079 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:59,080 - ModelServer - INFO - Received inference request
2025-01-17 18:31:59,382 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:59,387 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:31:59,399 - ModelServer - INFO - Received inference request
2025-01-17 18:31:59,700 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:31:59,702 - ModelServer - INFO - Received inference request
2025-01-17 18:32:00,079 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:00,080 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:00,081 - ModelServer - INFO - Received inference request
2025-01-17 18:32:00,400 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:00,401 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:00,402 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:00,404 - ModelServer - INFO - Received inference request
2025-01-17 18:32:00,756 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:00,764 - ModelServer - INFO - Received inference request
2025-01-17 18:32:01,090 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:01,092 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:01,093 - ModelServer - INFO - Received inference request
2025-01-17 18:32:01,375 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:01,381 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:01,382 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:01,388 - ModelServer - INFO - Received inference request
2025-01-17 18:32:01,713 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:01,715 - ModelServer - INFO - Received inference request
2025-01-17 18:32:02,022 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.64.192:38680 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:02,024 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20306 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:02,025 - ModelServer - INFO - Received inference request
2025-01-17 18:32:02,359 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:02,360 - ModelServer - INFO - Received inference request
2025-01-17 18:32:02,697 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:02,709 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:02,710 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:02,711 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:02,717 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.47.42:39982 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:02,762 - ModelServer - INFO - Received inference request
2025-01-17 18:32:03,192 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:03,199 - ModelServer - INFO - Received inference request
2025-01-17 18:32:03,501 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:03,502 - ModelServer - INFO - Received inference request
2025-01-17 18:32:03,790 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:03,791 - ModelServer - INFO - Received inference request
2025-01-17 18:32:04,097 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:04,109 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:04,110 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:04,111 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:04,112 - ModelServer - INFO - Received inference request
2025-01-17 18:32:04,477 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:04,479 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:04,485 - ModelServer - INFO - Received inference request
2025-01-17 18:32:04,848 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:04,858 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:04,859 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20306 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:04,862 - ModelServer - INFO - Received inference request
2025-01-17 18:32:05,156 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:05,169 - ModelServer - INFO - Received inference request
2025-01-17 18:32:05,462 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:05,464 - ModelServer - INFO - Received inference request
2025-01-17 18:32:05,779 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:05,780 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:12008 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:05,781 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:05,783 - ModelServer - INFO - Received inference request
2025-01-17 18:32:06,079 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:06,080 - ModelServer - INFO - Received inference request
2025-01-17 18:32:06,399 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:06,401 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:06,402 - ModelServer - INFO - Received inference request
2025-01-17 18:32:06,718 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:06,720 - ModelServer - INFO - Received inference request
2025-01-17 18:32:07,001 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:07,009 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:07,010 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:12018 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:07,011 - ModelServer - INFO - Received inference request
2025-01-17 18:32:07,325 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:07,339 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:07,340 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:07,342 - ModelServer - INFO - Received inference request
2025-01-17 18:32:07,662 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:07,663 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:07,664 - ModelServer - INFO - Received inference request
2025-01-17 18:32:07,939 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:07,941 - ModelServer - INFO - Received inference request
2025-01-17 18:32:08,214 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:08,217 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:08,229 - ModelServer - INFO - Received inference request
2025-01-17 18:32:08,520 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:08,521 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:08,522 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:08,523 - ModelServer - INFO - Received inference request
2025-01-17 18:32:08,806 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:08,807 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:08,819 - ModelServer - INFO - Received inference request
2025-01-17 18:32:09,110 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:09,119 - ModelServer - INFO - Received inference request
2025-01-17 18:32:09,467 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:09,468 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20306 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:09,470 - ModelServer - INFO - Received inference request
2025-01-17 18:32:09,789 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:09,790 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:09,791 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:09,793 - ModelServer - INFO - Received inference request
2025-01-17 18:32:10,091 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:10,099 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:10,100 - ModelServer - INFO - Received inference request
2025-01-17 18:32:10,376 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:10,378 - ModelServer - INFO - Received inference request
2025-01-17 18:32:10,667 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:10,679 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:10,681 - ModelServer - INFO - Received inference request
2025-01-17 18:32:10,976 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:10,989 - ModelServer - INFO - Received inference request
2025-01-17 18:32:11,263 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:11,264 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:41378 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:11,265 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20306 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:11,266 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:11,267 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.4.26:13794 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:11,286 - ModelServer - INFO - Received inference request
2025-01-17 18:32:11,578 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:11,580 - ModelServer - INFO - Received inference request
2025-01-17 18:32:11,866 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:11,873 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:11,876 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:11,898 - ModelServer - INFO - Received inference request
2025-01-17 18:32:12,216 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:12,229 - ModelServer - INFO - Received inference request
2025-01-17 18:32:12,515 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:12,530 - ModelServer - INFO - Received inference request
2025-01-17 18:32:12,849 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:12,850 - ModelServer - INFO - Received inference request
2025-01-17 18:32:13,134 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:13,135 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:13,136 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:13,137 - ModelServer - INFO - Received inference request
2025-01-17 18:32:13,435 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:13,449 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:13,450 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:13,452 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:13,478 - ModelServer - INFO - Received inference request
2025-01-17 18:32:13,767 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:13,777 - ModelServer - INFO - Received inference request
2025-01-17 18:32:14,117 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:14,129 - ModelServer - INFO - Received inference request
2025-01-17 18:32:14,455 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:14,457 - ModelServer - INFO - Received inference request
2025-01-17 18:32:14,752 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:14,754 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:14,755 - ModelServer - INFO - Received inference request
2025-01-17 18:32:15,046 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:15,054 - ModelServer - INFO - Received inference request
2025-01-17 18:32:15,377 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:15,380 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:15,389 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:15,390 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:15,391 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:15,391 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:15,394 - ModelServer - INFO - Received inference request
2025-01-17 18:32:15,723 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:15,738 - ModelServer - INFO - Received inference request
2025-01-17 18:32:16,044 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:16,046 - ModelServer - INFO - Received inference request
2025-01-17 18:32:16,348 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:16,359 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:35200 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:16,365 - ModelServer - INFO - Received inference request
2025-01-17 18:32:16,685 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:16,689 - ModelServer - INFO - Received inference request
2025-01-17 18:32:16,988 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:16,990 - ModelServer - INFO - Received inference request
2025-01-17 18:32:17,328 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:17,339 - ModelServer - INFO - Received inference request
2025-01-17 18:32:17,635 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:17,646 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:17,647 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.64.192:51690 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:17,649 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:17,650 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:35214 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:17,650 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:17,653 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.47.42:17594 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:17,669 - ModelServer - INFO - Received inference request
2025-01-17 18:32:17,987 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:18,010 - ModelServer - INFO - Received inference request
2025-01-17 18:32:18,342 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:18,349 - ModelServer - INFO - Received inference request
2025-01-17 18:32:18,640 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:18,645 - ModelServer - INFO - Received inference request
2025-01-17 18:32:18,949 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:18,959 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:18,960 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:18,961 - ModelServer - INFO - Received inference request
2025-01-17 18:32:19,257 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:19,269 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:19,270 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:19,272 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:35200 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:19,298 - ModelServer - INFO - Received inference request
2025-01-17 18:32:19,580 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:19,587 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:19,783 - ModelServer - INFO - Received inference request
2025-01-17 18:32:20,055 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:20,069 - ModelServer - INFO - Received inference request
2025-01-17 18:32:20,368 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:20,378 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:20,379 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:20,405 - ModelServer - INFO - Received inference request
2025-01-17 18:32:20,689 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:20,691 - ModelServer - INFO - Received inference request
2025-01-17 18:32:21,006 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:21,010 - ModelServer - INFO - Received inference request
2025-01-17 18:32:21,314 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:21,319 - ModelServer - INFO - Received inference request
2025-01-17 18:32:21,616 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:21,628 - ModelServer - INFO - Received inference request
2025-01-17 18:32:21,922 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:21,929 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:21,930 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:21,931 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:21,931 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:21,932 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:21,939 - ModelServer - INFO - Received inference request
2025-01-17 18:32:22,278 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:22,283 - ModelServer - INFO - Received inference request
2025-01-17 18:32:22,565 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:22,579 - ModelServer - INFO - Received inference request
2025-01-17 18:32:22,919 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:22,920 - ModelServer - INFO - Received inference request
2025-01-17 18:32:23,227 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:23,239 - ModelServer - INFO - Received inference request
2025-01-17 18:32:23,520 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:23,521 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:23,522 - ModelServer - INFO - Received inference request
2025-01-17 18:32:23,804 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:23,805 - ModelServer - INFO - Received inference request
2025-01-17 18:32:24,100 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:24,102 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:24,103 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:35214 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:24,103 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:24,104 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:24,105 - ModelServer - INFO - Received inference request
2025-01-17 18:32:24,446 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:24,447 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:24,458 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:35200 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:24,462 - ModelServer - INFO - Received inference request
2025-01-17 18:32:24,769 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:24,779 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:17598 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:24,780 - ModelServer - INFO - Received inference request
2025-01-17 18:32:25,098 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:25,100 - ModelServer - INFO - Received inference request
2025-01-17 18:32:25,376 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:25,377 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:25,379 - ModelServer - INFO - Received inference request
2025-01-17 18:32:25,665 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:25,666 - ModelServer - INFO - Received inference request
2025-01-17 18:32:26,000 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:26,001 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:26,002 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:26,003 - ModelServer - INFO - Received inference request
2025-01-17 18:32:26,320 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:26,321 - ModelServer - INFO - Received inference request
2025-01-17 18:32:26,622 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:26,629 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:26,630 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:26,631 - ModelServer - INFO - Received inference request
2025-01-17 18:32:26,912 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.4.26:21046 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:26,920 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:35200 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:26,922 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:26,923 - ModelServer - INFO - Received inference request
2025-01-17 18:32:27,195 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:27,209 - ModelServer - INFO - Received inference request
2025-01-17 18:32:27,487 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:27,499 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:27,500 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:10662 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:27,508 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:27,511 - ModelServer - INFO - Received inference request
2025-01-17 18:32:27,831 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:27,833 - ModelServer - INFO - Received inference request
2025-01-17 18:32:28,115 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:28,129 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:21058 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:28,131 - ModelServer - INFO - Received inference request
2025-01-17 18:32:28,415 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:28,416 - ModelServer - INFO - Received inference request
2025-01-17 18:32:28,713 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:28,729 - ModelServer - INFO - Received inference request
2025-01-17 18:32:29,052 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:29,059 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:29,061 - ModelServer - INFO - Received inference request
2025-01-17 18:32:29,375 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:29,379 - ModelServer - INFO - Received inference request
2025-01-17 18:32:29,710 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:29,719 - ModelServer - INFO - Received inference request
2025-01-17 18:32:30,004 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:30,009 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:30,010 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:30,011 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:30,019 - ModelServer - INFO - Received inference request
2025-01-17 18:32:30,306 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:30,319 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:30,320 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:30,322 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:30,324 - ModelServer - INFO - Received inference request
2025-01-17 18:32:30,667 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:30,668 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:17598 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:30,675 - ModelServer - INFO - Received inference request
2025-01-17 18:32:30,986 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:30,998 - ModelServer - INFO - Received inference request
2025-01-17 18:32:31,312 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:31,314 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:49742 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:31,315 - ModelServer - INFO - Received inference request
2025-01-17 18:32:31,630 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:31,631 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:31,638 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:31,640 - ModelServer - INFO - Received inference request
2025-01-17 18:32:31,925 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:31,939 - ModelServer - INFO - Received inference request
2025-01-17 18:32:32,272 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.64.192:10672 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:32,273 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:32,275 - ModelServer - INFO - Received inference request
2025-01-17 18:32:32,573 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:32,581 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:32,588 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:32,590 - ModelServer - INFO - Received inference request
2025-01-17 18:32:32,905 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:32,919 - ModelServer - INFO - Received inference request
2025-01-17 18:32:33,261 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:33,263 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:17598 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:33,264 - ModelServer - INFO - Received inference request
2025-01-17 18:32:33,546 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:33,559 - ModelServer - INFO - Received inference request
2025-01-17 18:32:33,862 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.47.42:49754 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:33,864 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:47260 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:33,865 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:33,866 - ModelServer - INFO - Received inference request
2025-01-17 18:32:34,162 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:34,164 - ModelServer - INFO - Received inference request
2025-01-17 18:32:34,540 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:34,542 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:34,542 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:34,543 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:34,546 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:34,547 - ModelServer - INFO - Received inference request
2025-01-17 18:32:34,883 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:34,885 - ModelServer - INFO - Received inference request
2025-01-17 18:32:35,195 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:35,196 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:19794 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:35,208 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:35,228 - ModelServer - INFO - Received inference request
2025-01-17 18:32:35,543 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:35,549 - ModelServer - INFO - Received inference request
2025-01-17 18:32:35,869 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:35,871 - ModelServer - INFO - Received inference request
2025-01-17 18:32:36,176 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:36,179 - ModelServer - INFO - Received inference request
2025-01-17 18:32:36,488 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:36,499 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:36,501 - ModelServer - INFO - Received inference request
2025-01-17 18:32:36,776 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:36,789 - ModelServer - INFO - Received inference request
2025-01-17 18:32:37,079 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:37,080 - ModelServer - INFO - Received inference request
2025-01-17 18:32:37,410 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:37,411 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:37,418 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:37,419 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:37,420 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:37,421 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:49742 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:37,421 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:17598 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:37,425 - ModelServer - INFO - Received inference request
2025-01-17 18:32:37,736 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:37,750 - ModelServer - INFO - Received inference request
2025-01-17 18:32:38,049 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:38,050 - ModelServer - INFO - Received inference request
2025-01-17 18:32:38,351 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:38,359 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:47270 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:38,360 - ModelServer - INFO - Received inference request
2025-01-17 18:32:38,636 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:38,639 - ModelServer - INFO - Received inference request
2025-01-17 18:32:38,965 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:38,967 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:38,968 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:38,974 - ModelServer - INFO - Received inference request
2025-01-17 18:32:39,262 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:39,263 - ModelServer - INFO - Received inference request
2025-01-17 18:32:39,592 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:39,593 - ModelServer - INFO - Received inference request
2025-01-17 18:32:39,881 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:39,889 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:39,890 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:39,891 - ModelServer - INFO - Received inference request
2025-01-17 18:32:40,260 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:40,261 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:40,262 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:40,264 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:19794 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:40,265 - ModelServer - INFO - Received inference request
2025-01-17 18:32:40,589 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:40,591 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:17598 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:40,592 - ModelServer - INFO - Received inference request
2025-01-17 18:32:40,893 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:40,894 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:49742 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:40,895 - ModelServer - INFO - Received inference request
2025-01-17 18:32:41,196 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:41,209 - ModelServer - INFO - Received inference request
2025-01-17 18:32:41,474 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:41,486 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:41,487 - ModelServer - INFO - Received inference request
2025-01-17 18:32:41,776 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.4.26:19798 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:41,785 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:41,786 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:41,788 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:41,801 - ModelServer - INFO - Received inference request
2025-01-17 18:32:42,085 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:42,096 - ModelServer - INFO - Received inference request
2025-01-17 18:32:42,410 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:42,411 - ModelServer - INFO - Received inference request
2025-01-17 18:32:42,692 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:42,699 - ModelServer - INFO - Received inference request
2025-01-17 18:32:43,003 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:43,005 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:43,009 - ModelServer - INFO - Received inference request
2025-01-17 18:32:43,311 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:43,319 - ModelServer - INFO - Received inference request
2025-01-17 18:32:43,598 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:43,605 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:43,606 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:43,607 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:43,608 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:43,618 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:43,620 - ModelServer - INFO - Received inference request
2025-01-17 18:32:43,952 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:43,954 - ModelServer - INFO - Received inference request
2025-01-17 18:32:44,322 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:44,329 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:47590 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:44,330 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:44,348 - ModelServer - INFO - Received inference request
2025-01-17 18:32:44,690 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:44,699 - ModelServer - INFO - Received inference request
2025-01-17 18:32:44,996 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:45,007 - ModelServer - INFO - Received inference request
2025-01-17 18:32:45,300 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:45,301 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:45,309 - ModelServer - INFO - Received inference request
2025-01-17 18:32:45,592 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:45,599 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:45,600 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:45,602 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:45,620 - ModelServer - INFO - Received inference request
2025-01-17 18:32:45,934 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:45,949 - ModelServer - INFO - Received inference request
2025-01-17 18:32:46,241 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:46,242 - ModelServer - INFO - Received inference request
2025-01-17 18:32:46,522 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:46,524 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:46,535 - ModelServer - INFO - Received inference request
2025-01-17 18:32:46,835 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:46,837 - ModelServer - INFO - Received inference request
2025-01-17 18:32:47,165 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:47,167 - ModelServer - INFO - Received inference request
2025-01-17 18:32:47,491 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.64.192:60422 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:47,493 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:47,494 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:47,495 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:47,495 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:47,498 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:47,502 - ModelServer - INFO - Received inference request
2025-01-17 18:32:47,788 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:47,790 - ModelServer - INFO - Received inference request
2025-01-17 18:32:48,163 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.47.42:52522 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:48,172 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:47598 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:48,174 - ModelServer - INFO - Received inference request
2025-01-17 18:32:48,457 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:48,469 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:48,470 - ModelServer - INFO - Received inference request
2025-01-17 18:32:48,765 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:48,766 - ModelServer - INFO - Received inference request
2025-01-17 18:32:49,076 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:49,089 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:49,090 - ModelServer - INFO - Received inference request
2025-01-17 18:32:49,414 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:49,429 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:49,430 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:49,433 - ModelServer - INFO - Received inference request
2025-01-17 18:32:49,714 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:49,715 - ModelServer - INFO - Received inference request
2025-01-17 18:32:50,003 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:50,004 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:50,009 - ModelServer - INFO - Received inference request
2025-01-17 18:32:50,323 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:50,339 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:50,340 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:50,342 - ModelServer - INFO - Received inference request
2025-01-17 18:32:50,623 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:50,624 - ModelServer - INFO - Received inference request
2025-01-17 18:32:50,917 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:50,923 - ModelServer - INFO - Received inference request
2025-01-17 18:32:51,228 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:51,235 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52538 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:51,236 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:51,237 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:51,238 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52542 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:51,259 - ModelServer - INFO - Received inference request
2025-01-17 18:32:51,592 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:51,599 - ModelServer - INFO - Received inference request
2025-01-17 18:32:51,907 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:51,919 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:51,920 - ModelServer - INFO - Received inference request
2025-01-17 18:32:52,250 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:52,252 - ModelServer - INFO - Received inference request
2025-01-17 18:32:52,561 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:52,562 - ModelServer - INFO - Received inference request
2025-01-17 18:32:52,870 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:52,871 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:52,879 - ModelServer - INFO - Received inference request
2025-01-17 18:32:53,163 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:53,165 - ModelServer - INFO - Received inference request
2025-01-17 18:32:53,443 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:53,449 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:53,450 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52538 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:53,450 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:53,452 - ModelServer - INFO - Received inference request
2025-01-17 18:32:53,765 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:53,779 - ModelServer - INFO - Received inference request
2025-01-17 18:32:54,093 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:54,095 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:54,099 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:54,101 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:51694 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:54,109 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52542 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:54,119 - ModelServer - INFO - Received inference request
2025-01-17 18:32:54,455 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:54,470 - ModelServer - INFO - Received inference request
2025-01-17 18:32:54,787 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:54,799 - ModelServer - INFO - Received inference request
2025-01-17 18:32:55,082 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:55,084 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:55,089 - ModelServer - INFO - Received inference request
2025-01-17 18:32:55,378 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:55,389 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:55,390 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:55,392 - ModelServer - INFO - Received inference request
2025-01-17 18:32:55,708 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:55,719 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:55,720 - ModelServer - INFO - Received inference request
2025-01-17 18:32:56,028 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:56,030 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52538 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:56,031 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.4.26:39568 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:32:56,048 - ModelServer - INFO - Received inference request
2025-01-17 18:32:56,359 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:56,360 - ModelServer - INFO - Received inference request
2025-01-17 18:32:56,685 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:56,689 - ModelServer - INFO - Received inference request
2025-01-17 18:32:56,993 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:56,994 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:56,995 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:56,996 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:57,048 - ModelServer - INFO - Received inference request
2025-01-17 18:32:57,390 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:57,391 - ModelServer - INFO - Received inference request
2025-01-17 18:32:57,718 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:57,719 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:57,721 - ModelServer - INFO - Received inference request
2025-01-17 18:32:58,016 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:58,019 - ModelServer - INFO - Received inference request
2025-01-17 18:32:58,324 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:58,325 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:58,339 - ModelServer - INFO - Received inference request
2025-01-17 18:32:58,661 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:58,663 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:58,664 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:58,664 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:58,684 - ModelServer - INFO - Received inference request
2025-01-17 18:32:59,005 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:59,007 - ModelServer - INFO - Received inference request
2025-01-17 18:32:59,292 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:59,299 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:59,300 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:59,320 - ModelServer - INFO - Received inference request
2025-01-17 18:32:59,645 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:59,647 - ModelServer - INFO - Received inference request
2025-01-17 18:32:59,956 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:32:59,969 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:32:59,970 - ModelServer - INFO - Received inference request
2025-01-17 18:33:00,280 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:00,281 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:00,282 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:00,299 - ModelServer - INFO - Received inference request
2025-01-17 18:33:00,600 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:00,601 - ModelServer - INFO - Received inference request
2025-01-17 18:33:00,897 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:00,909 - ModelServer - INFO - Received inference request
2025-01-17 18:33:01,183 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:01,189 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:01,190 - ModelServer - INFO - Received inference request
2025-01-17 18:33:01,497 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:01,509 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:01,510 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:01,512 - ModelServer - INFO - Received inference request
2025-01-17 18:33:01,807 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.64.192:49688 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:01,819 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:01,821 - ModelServer - INFO - Received inference request
2025-01-17 18:33:02,091 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:02,097 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:02,109 - ModelServer - INFO - Received inference request
2025-01-17 18:33:02,482 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:02,483 - ModelServer - INFO - Received inference request
2025-01-17 18:33:02,830 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:02,835 - ModelServer - INFO - Inference complete
2025-01-17 18:33:02,836 - ModelServer - INFO - Inference complete
2025-01-17 18:33:02,836 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.47.42:8180 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:02,859 - ModelServer - INFO - Received inference request
2025-01-17 18:33:03,274 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:03,275 - ModelServer - INFO - Received inference request
2025-01-17 18:33:03,612 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:03,618 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:03,619 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:03,688 - ModelServer - INFO - Received inference request
2025-01-17 18:33:04,007 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:04,015 - ModelServer - INFO - Received inference request
2025-01-17 18:33:04,381 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:04,390 - ModelServer - INFO - Received inference request
2025-01-17 18:33:04,723 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:04,724 - ModelServer - INFO - Received inference request
2025-01-17 18:33:05,013 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:05,019 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:05,022 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:05,029 - ModelServer - INFO - Received inference request
2025-01-17 18:33:05,333 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:05,349 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:05,350 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:05,352 - ModelServer - INFO - Received inference request
2025-01-17 18:33:05,672 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:05,678 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:05,688 - ModelServer - INFO - Received inference request
2025-01-17 18:33:06,005 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:06,019 - ModelServer - INFO - Received inference request
2025-01-17 18:33:06,343 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:06,344 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:06,347 - ModelServer - INFO - Received inference request
2025-01-17 18:33:06,667 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:06,675 - ModelServer - INFO - Received inference request
2025-01-17 18:33:07,013 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:07,015 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27072 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:07,019 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:07,020 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:07,020 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:07,029 - ModelServer - INFO - Received inference request
2025-01-17 18:33:07,382 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:07,390 - ModelServer - INFO - Received inference request
2025-01-17 18:33:07,677 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:07,689 - ModelServer - INFO - Received inference request
2025-01-17 18:33:07,983 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:07,984 - ModelServer - INFO - Received inference request
2025-01-17 18:33:08,311 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:08,319 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:50442 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:08,320 - ModelServer - INFO - Received inference request
2025-01-17 18:33:08,608 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:08,609 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:08,610 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:08,612 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:56338 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:08,613 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:08,638 - ModelServer - INFO - Received inference request
2025-01-17 18:33:08,936 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:08,949 - ModelServer - INFO - Received inference request
2025-01-17 18:33:09,262 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:09,264 - ModelServer - INFO - Received inference request
2025-01-17 18:33:09,555 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:09,569 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:09,569 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:09,570 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:09,768 - ModelServer - INFO - Received inference request
2025-01-17 18:33:09,960 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:09,962 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:10,059 - ModelServer - INFO - Received inference request
2025-01-17 18:33:10,340 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:10,342 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:10,685 - ModelServer - INFO - Received inference request
2025-01-17 18:33:10,916 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:10,929 - ModelServer - INFO - Received inference request
2025-01-17 18:33:11,197 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:11,209 - ModelServer - INFO - Received inference request
2025-01-17 18:33:11,514 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:11,515 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:11,519 - ModelServer - INFO - Received inference request
2025-01-17 18:33:11,822 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:11,829 - ModelServer - INFO - Received inference request
2025-01-17 18:33:12,193 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.4.26:50452 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:12,197 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:12,198 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:12,199 - ModelServer - INFO - Received inference request
2025-01-17 18:33:12,520 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:12,523 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:12,530 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:12,532 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:12,533 - ModelServer - INFO - Received inference request
2025-01-17 18:33:12,809 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:12,811 - ModelServer - INFO - Received inference request
2025-01-17 18:33:13,123 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:13,129 - ModelServer - INFO - Received inference request
2025-01-17 18:33:13,423 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:13,428 - ModelServer - INFO - Received inference request
2025-01-17 18:33:13,733 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:13,734 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:13704 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:13,735 - ModelServer - INFO - Received inference request
2025-01-17 18:33:14,067 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:14,079 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:13710 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:14,089 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:20300 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:14,090 - ModelServer - INFO - Received inference request
2025-01-17 18:33:14,437 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:14,449 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:14,451 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:14,453 - ModelServer - INFO - Received inference request
2025-01-17 18:33:14,753 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:14,754 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:14,756 - ModelServer - INFO - Received inference request
2025-01-17 18:33:15,093 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:15,104 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:13704 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:15,105 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:15,129 - ModelServer - INFO - Received inference request
2025-01-17 18:33:15,448 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:15,459 - ModelServer - INFO - Received inference request
2025-01-17 18:33:15,745 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:15,746 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:15,747 - ModelServer - INFO - Received inference request
2025-01-17 18:33:16,098 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:16,099 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:16,101 - ModelServer - INFO - Received inference request
2025-01-17 18:33:16,449 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:16,450 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.64.192:42688 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:16,451 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:16,479 - ModelServer - INFO - Received inference request
2025-01-17 18:33:16,822 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:16,839 - ModelServer - INFO - Received inference request
2025-01-17 18:33:17,115 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:17,129 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:17,130 - ModelServer - INFO - Received inference request
2025-01-17 18:33:17,435 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:17,443 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:17,444 - ModelServer - INFO - Received inference request
2025-01-17 18:33:17,772 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:17,774 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.47.42:39280 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:17,775 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:17,795 - ModelServer - INFO - Received inference request
2025-01-17 18:33:18,096 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:18,109 - ModelServer - INFO - Received inference request
2025-01-17 18:33:18,406 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:18,420 - ModelServer - INFO - Received inference request
2025-01-17 18:33:18,702 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:18,703 - ModelServer - INFO - Received inference request
2025-01-17 18:33:19,027 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:19,036 - ModelServer - INFO - Received inference request
2025-01-17 18:33:19,353 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:19,354 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:19,355 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:19,356 - ModelServer - INFO - Received inference request
2025-01-17 18:33:19,635 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:19,637 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:19,638 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:19,647 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:19,648 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:19,649 - ModelServer - INFO - Received inference request
2025-01-17 18:33:19,936 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:19,952 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42698 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:19,974 - ModelServer - INFO - Received inference request
2025-01-17 18:33:20,283 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:20,290 - ModelServer - INFO - Received inference request
2025-01-17 18:33:20,592 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:20,599 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:20,600 - ModelServer - INFO - Received inference request
2025-01-17 18:33:20,901 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:20,909 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:20,910 - ModelServer - INFO - Received inference request
2025-01-17 18:33:21,206 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:21,219 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:21,220 - ModelServer - INFO - Received inference request
2025-01-17 18:33:21,517 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:21,529 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:21,530 - ModelServer - INFO - Received inference request
2025-01-17 18:33:21,840 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:21,849 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:21,850 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:21,869 - ModelServer - INFO - Received inference request
2025-01-17 18:33:22,189 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:22,197 - ModelServer - INFO - Received inference request
2025-01-17 18:33:22,536 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:22,549 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:22,550 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:22,555 - ModelServer - INFO - Received inference request
2025-01-17 18:33:22,859 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:22,860 - ModelServer - INFO - Received inference request
2025-01-17 18:33:23,206 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:23,207 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:23,208 - ModelServer - INFO - Received inference request
2025-01-17 18:33:23,510 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:23,511 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:23,518 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:23,538 - ModelServer - INFO - Received inference request
2025-01-17 18:33:23,819 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:23,821 - ModelServer - INFO - Received inference request
2025-01-17 18:33:24,135 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:24,139 - ModelServer - INFO - Received inference request
2025-01-17 18:33:24,502 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:24,503 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:24,505 - ModelServer - INFO - Received inference request
2025-01-17 18:33:24,842 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:24,843 - ModelServer - INFO - Received inference request
2025-01-17 18:33:25,170 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:25,178 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:25,179 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:25,181 - ModelServer - INFO - Received inference request
2025-01-17 18:33:25,467 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:25,469 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:25,471 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:25,472 - ModelServer - INFO - Received inference request
2025-01-17 18:33:25,794 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:25,795 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42698 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:25,797 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.4.26:32310 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:25,826 - ModelServer - INFO - Received inference request
2025-01-17 18:33:26,167 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:26,179 - ModelServer - INFO - Received inference request
2025-01-17 18:33:26,474 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:26,475 - ModelServer - INFO - Received inference request
2025-01-17 18:33:26,848 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:26,850 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:26,850 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:26,851 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:27,038 - ModelServer - INFO - Received inference request
2025-01-17 18:33:27,363 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:27,368 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:28,314 - ModelServer - INFO - Received inference request
2025-01-17 18:33:28,576 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:28,598 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:28,615 - ModelServer - INFO - Received inference request
2025-01-17 18:33:28,917 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:28,929 - ModelServer - INFO - Received inference request
2025-01-17 18:33:29,220 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:29,221 - ModelServer - INFO - Received inference request
2025-01-17 18:33:29,518 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:29,519 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:29,521 - ModelServer - INFO - Received inference request
2025-01-17 18:33:29,796 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:29,809 - ModelServer - INFO - Received inference request
2025-01-17 18:33:30,097 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:30,109 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:30,110 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:30,110 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:30,111 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:30,138 - ModelServer - INFO - Received inference request
2025-01-17 18:33:30,473 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:30,488 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.64.192:26548 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:31,546 - ModelServer - INFO - Received inference request
2025-01-17 18:33:31,882 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:31,883 - ModelServer - INFO - Received inference request
2025-01-17 18:33:32,188 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:32,189 - ModelServer - INFO - Received inference request
2025-01-17 18:33:32,492 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:32,493 - ModelServer - INFO - Received inference request
2025-01-17 18:33:32,777 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:32,789 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:32,799 - ModelServer - INFO - Received inference request
2025-01-17 18:33:33,122 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:33,129 - ModelServer - INFO - Received inference request
2025-01-17 18:33:33,446 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:33,459 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:33,460 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:33,461 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.47.42:9598 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:33,462 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:33,465 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:33,466 - ModelServer - INFO - Received inference request
2025-01-17 18:33:33,816 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:33,818 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:24986 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:33,839 - ModelServer - INFO - Received inference request
2025-01-17 18:33:34,066 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:34,068 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:34,252 - ModelServer - INFO - Received inference request
2025-01-17 18:33:34,452 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:34,454 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:34,539 - ModelServer - INFO - Received inference request
2025-01-17 18:33:34,833 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:34,858 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:35,081 - ModelServer - INFO - Received inference request
2025-01-17 18:33:35,369 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:35,370 - ModelServer - INFO - Received inference request
2025-01-17 18:33:35,651 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:35,656 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:35,658 - ModelServer - INFO - Received inference request
2025-01-17 18:33:36,014 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:36,029 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:36,039 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:36,078 - ModelServer - INFO - Received inference request
2025-01-17 18:33:36,420 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:36,421 - ModelServer - INFO - Received inference request
2025-01-17 18:33:36,713 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:36,718 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:36,719 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:36,948 - ModelServer - INFO - Received inference request
2025-01-17 18:33:37,265 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:37,278 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:37,578 - ModelServer - INFO - Received inference request
2025-01-17 18:33:37,905 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:37,907 - ModelServer - INFO - Received inference request
2025-01-17 18:33:38,195 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:38,209 - ModelServer - INFO - Received inference request
2025-01-17 18:33:38,522 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:38,523 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:38,525 - ModelServer - INFO - Received inference request
2025-01-17 18:33:38,827 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:38,829 - ModelServer - INFO - Received inference request
2025-01-17 18:33:39,155 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:39,169 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:39,169 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:39,170 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:39,172 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:39,766 - ModelServer - INFO - Received inference request
2025-01-17 18:33:40,042 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:40,044 - ModelServer - INFO - Received inference request
2025-01-17 18:33:40,344 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:40,345 - ModelServer - INFO - Received inference request
2025-01-17 18:33:40,658 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:40,659 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:40,668 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:40,669 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:40,679 - ModelServer - INFO - Received inference request
2025-01-17 18:33:40,996 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:41,009 - ModelServer - INFO - Received inference request
2025-01-17 18:33:41,302 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:41,303 - ModelServer - INFO - Received inference request
2025-01-17 18:33:41,595 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:41,609 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:41,610 - ModelServer - INFO - Received inference request
2025-01-17 18:33:41,855 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
INFO:     192.168.4.26:24988 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:41,857 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:41,858 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:41,860 - ModelServer - INFO - Received inference request
2025-01-17 18:33:42,223 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:42,240 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:42,241 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:42,243 - ModelServer - INFO - Received inference request
2025-01-17 18:33:42,543 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:42,545 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:6182 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:42,561 - ModelServer - INFO - Received inference request
2025-01-17 18:33:42,884 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:42,889 - ModelServer - INFO - Received inference request
2025-01-17 18:33:43,205 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:43,219 - ModelServer - INFO - Received inference request
2025-01-17 18:33:43,539 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:43,540 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:43,541 - ModelServer - INFO - Received inference request
2025-01-17 18:33:43,846 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:43,847 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:43,847 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:43,860 - ModelServer - INFO - Received inference request
2025-01-17 18:33:44,224 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:44,224 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:44,230 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:44,502 - ModelServer - INFO - Received inference request
2025-01-17 18:33:44,791 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:44,808 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:45,076 - ModelServer - INFO - Received inference request
2025-01-17 18:33:45,259 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:45,261 - ModelServer - INFO - Received inference request
2025-01-17 18:33:45,542 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:45,545 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:45,546 - ModelServer - INFO - Received inference request
2025-01-17 18:33:45,864 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:45,865 - ModelServer - INFO - Received inference request
2025-01-17 18:33:46,200 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:46,201 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:46,209 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:46,211 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.64.192:6184 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:46,459 - ModelServer - INFO - Received inference request
2025-01-17 18:33:46,704 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:46,708 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.47.42:38874 - "GET / HTTP/1.1" 404 Not Found
2025-01-17 18:33:47,407 - ModelServer - INFO - Received inference request
2025-01-17 18:33:47,712 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:47,717 - ModelServer - INFO - Received inference request
2025-01-17 18:33:48,041 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:48,045 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:48,046 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55552 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:48,064 - ModelServer - INFO - Received inference request
2025-01-17 18:33:48,342 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:48,344 - ModelServer - INFO - Received inference request
2025-01-17 18:33:48,627 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:48,628 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:48,630 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52080 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:48,678 - ModelServer - INFO - Received inference request
2025-01-17 18:33:48,963 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:48,965 - ModelServer - INFO - Received inference request
2025-01-17 18:33:49,260 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:49,261 - ModelServer - INFO - Received inference request
2025-01-17 18:33:49,542 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:49,543 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:42674 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:49,545 - ModelServer - INFO - Received inference request
2025-01-17 18:33:49,836 - ModelServer - INFO - Prediction complete. Top class: {'class': 'Dog', 'confidence': 0.9991511106491089}
2025-01-17 18:33:49,849 - ModelServer - INFO - Inference complete
INFO:     192.168.4.26:55582 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:49,849 - ModelServer - INFO - Inference complete
INFO:     192.168.64.192:27088 - "POST /infer HTTP/1.1" 200 OK
2025-01-17 18:33:49,851 - ModelServer - INFO - Inference complete
INFO:     192.168.47.42:52064 - "POST /infer HTTP/1.1" 200 OK
INFO:     192.168.4.26:10154 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:13802 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:41568 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:7020 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:14910 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:5938 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:19832 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:25864 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:17828 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:28928 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:54968 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:25266 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:16794 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:20492 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:47700 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:59520 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:22588 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:40844 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:30308 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:10636 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:8048 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:6500 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:61914 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:12600 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:6768 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:15418 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:8414 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:33586 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:22292 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:8808 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:34026 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:3962 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:27156 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:37718 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:61950 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:7178 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:50230 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:28412 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:33724 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:13266 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:28728 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:28516 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:35220 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:47104 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:21488 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:14502 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:1024 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:12128 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:2928 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:51210 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:62118 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:16476 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:12156 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:41196 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:50930 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:6858 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:6590 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:50666 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:13548 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:17220 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:51908 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:4836 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:16872 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:25904 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:58848 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:9948 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:45234 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:33008 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:23432 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:18262 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:14104 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:60160 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:58982 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:48522 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:10130 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:11482 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:14376 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:40778 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:63716 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:5276 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:30874 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:8850 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:62994 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:36112 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:25292 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:36858 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:27726 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:13442 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:64466 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:51022 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:55896 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:19982 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:10846 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:60882 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:58872 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:48764 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:17536 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:18084 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:61298 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:39106 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:59620 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:51742 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:61504 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:53754 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:55110 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:51348 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:45396 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:8512 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:36988 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:14252 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:15420 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:61040 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:7178 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:43496 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:21998 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.64.192:35238 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.47.42:37420 - "GET / HTTP/1.1" 404 Not Found
INFO:     192.168.4.26:3648 - "GET / HTTP/1.1" 404 Not Found
